{
    "title": "Twitter scraper",
    "type": "object",
    "schemaVersion": 1,
    "properties": {
        "searchTerms": {
            "title": "Search terms",
            "type": "array",
            "prefill": ["Apify"],
            "editor": "stringList",
            "description": "Search for an specific terms and extract tweets for that term."
        },
        "handle": {
            "title": "Usernames",
            "type": "array",
            "description": "The twitter handles of the profiles you want to scrape. Shortcut instead of inputting https://twitter.com/username urls",
            "editor": "stringList"
        },
        "startUrls": {
            "title": "Start URLs",
            "description": "If you have a file or a url list of twitter urls, you provide them here",
            "default": [],
            "type": "array",
            "editor": "requestListSources"
        },
        "searchMode": {
            "title": "Search mode",
            "description": "Search mode changes the way the data is received",
            "editor": "select",
            "type": "string",
            "prefill": "",
            "enum": [
                "",
                "live",
                "user",
                "image",
                "video"
            ],
            "enumTitles": [
                "Top",
                "Latest",
                "People",
                "Photos",
                "Videos"
            ]
        },
        "mode": {
            "title": "Tweet types",
            "description": "Select the tweet types to get. Only tweets or tweets and replies for the selected handle when visiting profiles.",
            "type": "string",
            "editor": "select",
            "prefill": "replies",
            "default": "replies",
            "enumTitles": [
                "Only own tweets",
                "Own tweets and replies to other users"
            ],
            "enum": [
                "own",
                "replies"
            ]
        },
        "tweetsDesired": {
            "title": "Maximum number of tweets",
            "type": "integer",
            "description": "Maximum number of tweets to retrieve. Twitter have a default limit of around 3200 tweets. Check the README for workarounds.",
            "maximum": 3300,
            "prefill": 100,
            "default": 100
        },
        "addUserInfo": {
            "title": "Add user information",
            "description": "Appends an object to each tweet containing the user information. You can decrease the size of your dataset by turning this off.",
            "default": true,
            "type": "boolean",
            "editor": "checkbox"
        },
        "toDate": {
            "title": "Tweets newer than",
            "description": "Will get tweets that are newer than this date. Can be used in conjunction with 'Tweets older than' to create specific date slices. Can use specific dates, such as YYYY-MM-DD or relative ones, like '1 month' or '2 days'",
            "pattern": "(\\d{4}-\\d{2}-\\d{2}|(\\d+)\\s?\\S+)",
            "type": "string",
            "editor": "textfield",
            "sectionCaption": "Time frame",
            "sectionDescription": "You can choose a specific time window you want to scrape the tweets from."
        },
        "fromDate": {
            "title": "Tweets older than",
            "description": "Will start getting tweets from this date and older. Can be used in conjunction 'Tweets newer than'. Can use specific dates, such as YYYY-MM-DD or relative ones, like '1 month' or '2 days'",
            "type": "string",
            "pattern": "(\\d{4}-\\d{2}-\\d{2}|(\\d+)\\s?\\S+)",
            "editor": "textfield"
        },
        "proxyConfig": {
            "title": "Proxy configuration",
            "type": "object",
            "description": "It's required to use proxies when running on the platform.",
            "prefill": {
                "useApifyProxy": true
            },
            "default": {
                "useApifyProxy": true
            },
            "editor": "proxy",
            "sectionCaption": "Proxy configuration",
            "sectionDescription": "Choose what proxies you are going to use."

        },
        "extendOutputFunction": {
            "title": "Extend Output Function",
            "description": "Add or remove properties on the output object or omit the output returning null",
            "type": "string",
            "default": "async ({ data, item, page, request, customData, Apify }) => {\n  return item;\n}",
            "prefill": "async ({ data, item, page, request, customData, Apify }) => {\n  return item;\n}",
            "editor": "javascript",
            "sectionCaption": "Extend scraper functionality",
            "sectionDescription": "You can change the output of the items for your dataset here, or add additional behavior on the scraper."
        },
        "extendScraperFunction": {
            "title": "Extend Scraper Function",
            "description": "Advanced function that allows you to extend the default scraper functionality, allowing you to manually perform actions on the page",
            "type": "string",
            "default": "async ({ page, request, addSearch, addProfile, _, addThread, addEvent, customData, Apify, signal, label }) => {\n \n}",
            "prefill": "async ({ page, request, addSearch, addProfile, _, addThread, addEvent, customData, Apify, signal, label }) => {\n \n}",
            "editor": "javascript"
        },
        "customData": {
            "title": "Custom data",
            "description": "Any data that you want to have available inside the Extend Output/Scraper Function",
            "default": {},
            "prefill": {},
            "type": "object",
            "editor": "json"
        },
        "handlePageTimeoutSecs": {
            "title": "Max timeout seconds",
            "description": "Max timeout for the handlePageFunction. Can be increased for long running processes",
            "default": 5000,
            "prefill": 5000,
            "editor": "number",
            "type": "integer"
        },
        "stealth": {
            "title": "Stealth",
            "description": "Enabling stealth allows to decrease the chance of your scrape being detected as an automated process. Recommended to enable if you're providing your login cookies.",
            "default": false,
            "type": "boolean",
            "editor": "checkbox"
        },
        "maxRequestRetries": {
            "title": "Max request retries",
            "description": "Set the max request retries",
            "default": 3,
            "prefill": 3,
            "type": "integer",
            "editor": "number"
        },
        "maxIdleTimeoutSecs": {
            "title": "Scrolling idle seconds",
            "description": "Configures how many seconds of no data received to consider it done",
            "default": 30,
            "prefill": 30,
            "type": "integer",
            "editor": "number"
        },
        "debugLog": {
            "title": "Debug log",
            "description": "Enable debug log",
            "default": false,
            "type": "boolean",
            "editor": "checkbox"
        },
        "initialCookies": {
            "title": "Login cookies",
            "type": "array",
            "default": [],
            "prefill": [],
            "description": "Your login cookies will be used to bypass the login wall. See <a href='https://apify.com/vdrmota/twitter-scraper'>README</a> for instructions.",
            "editor": "json",
            "sectionCaption": "Login (optional)",
            "sectionDescription": "By providing login information you can have more access to data."
        }
    },
    "required": [
        "proxyConfig"
    ]
}
